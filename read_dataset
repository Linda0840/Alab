import json
import pandas as pd
from pandas import json_normalize
import csv
import numpy as np
from collections.abc import Mapping


################################################################## Linda: hashed_clarity_reports.csv ###################################################################################

df = pd.read_csv(
    "hashed_clarity_reports.csv",
    sep="|",
    engine="python",
    encoding="utf-8-sig",
    quoting=csv.QUOTE_NONE,   # ← treat " as a normal character
    escapechar="\\",          # backslash-escaped quotes like \" stay intact
    #nrows=1000,
    on_bad_lines="skip"       # or "warn"
)

JSON_COL = "CREDIT_REPORT"  # adjust to your actual column name

# --- 1. Safe parser for JSON strings ---
def parse_credit_report(x):
    """Convert the nested string into a dict."""
    if pd.isna(x):
        return None
    try:
        # The first loads() turns string → stringified JSON
        # The second loads() turns it into a dictionary
        return json.loads(json.loads(x))
    except Exception:
        return None

# --- 2. Parse all rows ---
parsed = df[JSON_COL].apply(parse_credit_report)

# --- 3. Extract the 'clear-bank-behavior' part ---
clear_behavior = parsed.apply(lambda d: d.get("clear-bank-behavior", {}) if isinstance(d, dict) else {})

# --- 4. Flatten each JSON dict into its own row ---
flat_df = json_normalize(clear_behavior.tolist(), sep=".")

# --- 5. Clean column names (optional but recommended) ---
flat_df.columns = (
    pd.Index(flat_df.columns)
    .str.replace(r"[^A-Za-z0-9]+", "_", regex=True)
    .str.strip("_")
    .str.lower()
)

# --- 6. Merge back with original df ---
hashed_clarity_reports = pd.concat([df.reset_index(drop=True), flat_df.reset_index(drop=True)], axis=1)

hashed_clarity_reports



################################################################## Ivy: hashed_emailage_reports.csv ###################################################################################

df = pd.read_csv(
    "hashed_emailage_reports.csv",
    sep="|",
    engine="python",
    encoding="utf-8-sig",
    quoting=csv.QUOTE_NONE,   # ← treat " as a normal character
    escapechar="\\",          # backslash-escaped quotes like \" stay intact
    on_bad_lines="skip"       # or "warn"
)

print(df.shape)
print(df.head(5))

import json
import pandas as pd
from pandas import json_normalize

JSON_COL = "CREDIT_REPORT"

def parse_credit_report(x):
    if pd.isna(x):
        return None
    try:
        return json.loads(x)
    except Exception:
        return None

parsed = df[JSON_COL].apply(parse_credit_report)

def _prefix_keys(dct, prefix):
    return {f"{prefix}.{k}": v for k, v in (dct or {}).items()}

def extract_all(d):
    if not isinstance(d, dict):
        return {}
    r = d.get("response", {}) or {}
    q = r.get("query", {}) or {}
    # Remove 'results' so we don't duplicate the item subtree
    q_no_results = {k: v for k, v in q.items() if k != "results"}

    item = (((q.get("results", {}) or {}).get("item", {}) or {}))
    rstatus = r.get("responseStatus", {}) or {}

    # Namespace query + responseStatus to avoid collisions with item keys
    out = {}
    out.update(_prefix_keys(q_no_results, "query"))
    out.update(item)  # item keys stay unprefixed (as before)
    out.update(_prefix_keys(rstatus, "responseStatus"))
    return out

combined = parsed.apply(extract_all)

flat_df = json_normalize(combined.tolist(), sep=".")
# Clean names (same as yours)
flat_df.columns = (
    pd.Index(flat_df.columns)
      .str.replace(r"[^A-Za-z0-9]+", "_", regex=True)
      .str.strip("_")
      .str.lower()
)

# Drop exact duplicate column names if any arose after cleaning
flat_df = flat_df.loc[:, ~flat_df.columns.duplicated()]

hashed_emailage_reports = pd.concat([df.reset_index(drop=True), flat_df.reset_index(drop=True)], axis=1)
print(hashed_emailage_reports.head(5))




################################################################## Frank: hashed_iovation_reports.csv ################################################

df = pd.read_csv(
    "hashed_iovation_reports.csv.gz",
    sep="|",
    engine="python",
    encoding="utf-8-sig",
    quoting=csv.QUOTE_NONE,   # ← treat " as a normal character
    escapechar="\\",          # backslash-escaped quotes like \" stay intact
    #nrows=10000,
    on_bad_lines="skip"       # or "warn"
)

# -----------------------------
# Utilities from before
# -----------------------------
def normalize_key(k: str) -> str:
    if ":" in k:
        k = k.split(":", 1)[1]
    if k.startswith("@"):
        return "attr." + k[1:]
    if k == "#text":
        return "text"
    return k

def flatten(obj, parent_key="", sep="."):
    flat = {}
    if isinstance(obj, Mapping):
        for k, v in obj.items():
            nk = normalize_key(k)
            key = f"{parent_key}{sep}{nk}" if parent_key else nk
            flat.update(flatten(v, key, sep))
    elif isinstance(obj, list):
        for i, v in enumerate(obj):
            key = f"{parent_key}[{i}]"
            flat.update(flatten(v, key, sep))
    else:
        flat[parent_key] = obj
    return flat

def get_details_map(d: dict) -> dict:
    try:
        env = d.get("SOAP-ENV:Envelope", {})
        body = env.get("SOAP-ENV:Body", {})
        resp = body.get("namesp1:CheckTransactionDetailsResponse", {})
        details = resp.get("namesp1:details", {}).get("namesp1:detail", [])
        out = {}
        for item in details:
            name = item.get("namesp1:name")
            value = item.get("namesp1:value")
            if name is not None:
                out[name] = value
        return out
    except Exception:
        return {}

# -----------------------------
# Apply to all CREDIT_REPORT entries
# -----------------------------
def parse_credit_report(json_str):
    try:
        data = json.loads(json_str)
        details = get_details_map(data)
        return details
    except Exception:
        return {}

# Apply to all rows
df_features = df_explore['CREDIT_REPORT'].apply(parse_credit_report)

# df_features is now a Series of dicts
# Convert to DataFrame (keys become columns)
df_iovation = pd.DataFrame(df_features.tolist())






################################################################## Ivy: hashed_iovation_reports.csv ################################################

customer_changes = pd.read_csv(
    "customer_changes.csv",
    sep="|",
    engine="python",
    encoding="utf-8-sig",
    quoting=csv.QUOTE_NONE,   # ← treat " as a normal character
    escapechar="\\",          # backslash-escaped quotes like \" stay intact
    on_bad_lines="skip"       # or "warn"
)

print(customer_changes.shape)
print(customer_changes.head(5))





